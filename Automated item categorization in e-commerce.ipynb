{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook shows how to develop SVM Classifier for automated Item Categorization using the products name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we prepare almost 20000 item titles from e-commerce platform and they are sampled from 19 category. 16000 item titles will be training data which contain titles and labels and the rest 4000 titles will be testing data without labels.\n",
    "```\n",
    "Input: Apple iPhone 8 Plus 64GB\n",
    "Label: Mobile & Gadget\n",
    "\n",
    "Input: Nike Running Shoes\n",
    "Label: Men's Shoes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#all_data is saved in an \"csv\" format\n",
    "\n",
    "DATA_PATH = \"/Users/daveyap/Desktop/github/handson session/data/train.csv\"\n",
    "all_data = pd.read_csv(DATA_PATH, encoding='utf-8')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a glimpse over our data\n",
    "##### item_title\n",
    "```\n",
    "A simple pre-processing has been done to filter emoj and other noisy letters. And all letters are transfromed to lower case.\n",
    "```\n",
    "##### label\n",
    "```\n",
    "Here, we only provide numbers as labels. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>women skirt cute ladies skirt ball gown sweet mini half fitting skirt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tempered glass stickers sony xz xa glass stickers</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hairclip hair grip pearl hairpins fashion creative gold zinc alloy headdress</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>making sugar craft cake mould cake decor baking tool sea coral silicone mold</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>korean style large capacity water glass plastic cup space cup outdoor sports ket</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        clean_title  \\\n",
       "0             women skirt cute ladies skirt ball gown sweet mini half fitting skirt   \n",
       "1                                 tempered glass stickers sony xz xa glass stickers   \n",
       "2      hairclip hair grip pearl hairpins fashion creative gold zinc alloy headdress   \n",
       "3      making sugar craft cake mould cake decor baking tool sea coral silicone mold   \n",
       "4  korean style large capacity water glass plastic cup space cup outdoor sports ket   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      8  \n",
       "2      6  \n",
       "3     11  \n",
       "4     11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 2000)  #show more\n",
    "all_data[['clean_title', 'label']].head(5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "- Text files are actually series of words (ordered).\n",
    "- In order to run machine learning algorithms we need to convert the text files into numerical feature vectors.\n",
    "- We will be using count vector models for our example.\n",
    "- Briefly, we segment each text file into words (for English splitting by space), and count # of times each word occurs in each document and finally assign each word an integer id. Each unique word in our dictionary will correspond to a feature dimension.\n",
    "##### Toy Corpus\n",
    "```\n",
    "Item 1: skirt office skirt\n",
    "Item 2: velle box pleated button down midi skirt.\n",
    "```\n",
    "##### Core Vocabulary\n",
    "```\n",
    "[skirt, office, velle, box, pleated, button, down, midi]\n",
    "```\n",
    "##### Vector Transformation\n",
    "```\n",
    "Item 1: [2, 1, 0, 0, 0, 0, 0, 0]\n",
    "Item 2: [1, 0, 1, 1, 1, 1, 1, 1]\n",
    "```\n",
    "Here, we are going to use a high-level API in SKlearn to learn count vectors from the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = all_data['clean_title'].tolist()\n",
    "all_labels = all_data['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating the bag of words...\\n\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's bag of words tool.  \n",
    "vectorizer = CountVectorizer(max_features = 10000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "all_data_features = vectorizer.fit_transform(all_titles)\n",
    "\n",
    "all_data_features = all_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.vocabulary_  #from word to index\n",
    "print (len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tempered glass stickers sony xz xa glass stickers\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "sample_id = 1\n",
    "vec_sample = all_data_features[sample_id,:]\n",
    "print (all_titles[sample_id])\n",
    "print (all_data_features[sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of tempered is 8340\n",
      "count of tempered is 1\n"
     ]
    }
   ],
   "source": [
    "sample_word = 'tempered'\n",
    "sample_count = all_data_features[sample_id][vocab[sample_word]]\n",
    "print (\"index of %s is %d\" %(sample_word, vocab[sample_word]))\n",
    "print (\"count of %s is %d\" %(sample_word, sample_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Model Training\n",
    " Here, we use linear SVM to classify the items into category.\n",
    " \n",
    " 16000 labelled item titles are splitted into training domain and validation domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training data is 12000\n",
      "# of testing data is 3987\n"
     ]
    }
   ],
   "source": [
    "train_x = all_data_features[:12000]\n",
    "train_y = all_labels[:12000]\n",
    "test_x = all_data_features[12000:]\n",
    "test_y = all_labels[12000:]\n",
    "print (\"# of training data is %d\" %len(train_x))\n",
    "print (\"# of testing data is %d\" %len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit the training data into SVM\n",
    "<img src='image_notebook/svm_illus.png'>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Initialize the \"LinearSVC\" object, which is scikit-learn's\n",
    "# linear SVM model.\n",
    "lin_clf = svm.LinearSVC()\n",
    "# fit( ) will do the model training, i.e., learn the model parameters\n",
    "lin_clf.fit(train_x, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing acc is 0.801605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# predict( ) will do the model prediction, predict y based on the input x\n",
    "predict_y = lin_clf.predict(test_x)\n",
    "print ('testing acc is %f' %accuracy_score(predict_y, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's brainstorming, the accuray is 80% 1/5 of the products wiould be categorized to wrong category. Seems like products name dataset would be too small for classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we would like to expand the data to increase the accuracy, what type of data we can acquire? From my view, the description of products seems like a great data to use and test for automated item categorization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daveyap_python",
   "language": "python",
   "name": "daveyap_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
